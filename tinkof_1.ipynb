{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost\n",
    "import time\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne.layers import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 80) \n",
    "pd.set_option('display.max_rows', 100) \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_reg(x):\n",
    "    if type(x) == type(1.0):\n",
    "        return u''\n",
    "    if x == 98:\n",
    "        return \n",
    "    x = x.upper()\n",
    "    x = x.replace(u'РЕСПУБЛИКА', u'')\n",
    "    x = x.replace(u'РЕСП', u'')\n",
    "    x = x.replace(u'ОБЛАСТЬ', u'')\n",
    "    x = x.replace(u'ОБЛ', u'')\n",
    "    x = x.replace(u'КРАЙ', u'')\n",
    "    x = x.replace(u'Г ', u'')\n",
    "    x = x.replace(u' Г', u'')\n",
    "    x = x.replace(u'Г.', u'')\n",
    "    x = x.replace(u'АО ', u'')\n",
    "    x = x.replace(u' АО', u'')\n",
    "    x = x.replace(u'АO', '')\n",
    "    x = x.replace(u'ЧУВАШСКАЯ', u'')\n",
    "    x = x.replace(u'(', u'')\n",
    "    x = x.replace(u')', u'')\n",
    "    x = x.replace(u'/', u'')\n",
    "    x = x.replace(u' ', u'')\n",
    "    x = x.replace(u'.', u'')\n",
    "    x = x.replace(u'-', u'')\n",
    "\n",
    "    x = x.replace(u'ЧУВАШСКАЯ', u'')\n",
    "    x = x.replace(u'ОРЁЛ', u'')\n",
    "    x = x.replace(u'СЕВЕРНАЯ', u'СЕВ')\n",
    "    if u'ЕВРЕЙ' in x:\n",
    "        x = u'ЕВРЕЙСКАЯАО'\n",
    "    if u'КАМЧ' in x:\n",
    "        x = u'КАМЧАТКА'\n",
    "    if u'ХАНТЫ' in x:\n",
    "        x = u'ХМАО'\n",
    "    if u'САХА' in x:\n",
    "        x = u'ЯКУТИЯ'\n",
    "    if u'АЛТАЙ' in x:\n",
    "        x = u'АЛТАЙ'\n",
    "    if u'МОСКОВСКИЙ' in x:\n",
    "        x = u'МОСКОВСКАЯ'\n",
    "    if u'МОСКВОС' in x:\n",
    "        x = u'МОСКОВСКАЯ'\n",
    "    if u'МОСКОВСКАЯ' in x:\n",
    "        x = u'МОСКОВСКАЯ'\n",
    "    if u'РОССИЯ' in x:\n",
    "        x = u'МОСКВА'\n",
    "    if u'ЧЕЛЯБ' in x:\n",
    "        x = u'ЧЕЛЯБИНСК'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(train, test):\n",
    "    \n",
    "    Xtest = test.copy()\n",
    "    X = train.drop(['open_account_flg'], axis=1).copy()\n",
    "    y = train['open_account_flg']\n",
    "    \n",
    "    for col in ['credit_sum', 'score_shk']:\n",
    "        X[col] = X[col].apply(lambda x: float(x.replace(',', '.')))\n",
    "        Xtest[col] = Xtest[col].apply(lambda x: float(x.replace(',', '.')))\n",
    "    \n",
    "    Xtest['conc'] = test['gender'] + test['marital_status'] + \\\n",
    "                    test['job_position'] + test['education']\n",
    "    X['conc'] = train['gender'] + train['marital_status'] + \\\n",
    "                train['job_position'] + train['education']\n",
    "        \n",
    "    encoder = LabelEncoder()\n",
    "    for col in ['gender', 'marital_status', 'education', 'job_position']:\n",
    "        X[col] = encoder.fit_transform(X[col])\n",
    "        Xtest[col] = encoder.transform(Xtest[col])\n",
    "    \n",
    "    for col in ['living_region', 'conc', 'living_region2']:\n",
    "        r1 = X[col].fillna('na')\n",
    "        r2 = Xtest[col].fillna('na')\n",
    "        encoder.fit(pd.concat([r1, r2]))\n",
    "        X[col] = encoder.transform(r1)\n",
    "        Xtest[col] = encoder.transform(r2)\n",
    "    \n",
    "    X.loc[X['monthly_income'].isnull(), 'monthly_income'] = X['monthly_income'].median()\n",
    "    \n",
    "    X = X.fillna(-1)\n",
    "    Xtest = Xtest.fillna(-1)\n",
    "    \n",
    "    for col in ['credit_sum', 'credit_month', 'living_region', 'living_region2']:\n",
    "        feature = pd.concat([X[col], Xtest[col]])\n",
    "        feature_map = feature.groupby(feature).apply(len)\n",
    "        X['frequency_' + col] = X[col].map(feature_map)\n",
    "        Xtest['frequency_' + col] = Xtest[col].map(feature_map)\n",
    "    \n",
    "    X['credit_sum_by_month'] = X.credit_sum / X.credit_month\n",
    "    Xtest['credit_sum_by_month'] = Xtest.credit_sum / Xtest.credit_month\n",
    "        \n",
    "    return X, Xtest, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_quantile(X, col, n):\n",
    "    X[col + '_quantile'] = pd.qcut(X[col], n)\n",
    "    return pd.get_dummies(X, columns=[col + '_quantile'])\n",
    "def create_linear(X):\n",
    "    columns = ['marital_status', 'job_position', 'tariff_id', \n",
    "               'education', 'living_region', 'living_region2', \n",
    "               'age', 'credit_month', 'overdue_credit_count', 'credit_count']\n",
    "    X_linear = pd.get_dummies(X.drop('conc', axis=1), columns=columns)\n",
    "        \n",
    "    X_linear = create_quantile(X_linear, 'credit_sum', 20)\n",
    "    X_linear = create_quantile(X_linear, 'score_shk', 30)\n",
    "    X_linear = create_quantile(X_linear, 'credit_sum_by_month', 50)\n",
    "    X_linear = create_quantile(X_linear, 'frequency_credit_sum', 6)\n",
    "    \n",
    "    X_linear.credit_sum_by_month = np.log(X_linear.credit_sum_by_month)\n",
    "    X_linear.frequency_credit_sum = np.log(X_linear.frequency_credit_sum)\n",
    "    \n",
    "    X_linear = X_linear.drop(['frequency_credit_month', 'frequency_living_region', 'frequency_living_region2'], axis=1)\n",
    "    return minmax_scale(X_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"../data/credit_train.csv\", encoding='cp1251', sep=';', index_col='client_id')\n",
    "data_test = pd.read_csv(\"../data/credit_test.csv\", encoding='cp1251', sep=';', index_col='client_id')\n",
    "\n",
    "data_test['living_region2'] = data_test['living_region'].apply(normalize_reg)\n",
    "data_train['living_region2'] = data_train['living_region'].apply(normalize_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Xtest, y = preprocessing(data_train, data_test)\n",
    "X_tmp = create_linear(pd.concat([X, Xtest]))\n",
    "X_linear = X_tmp[:len(X)]\n",
    "Xtest_linear = X_tmp[len(X):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    \n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]\n",
    "\n",
    "def proba_from_nn(Xtrain, Xtest, ytrain):\n",
    "    \n",
    "    ytrain = np.array(ytrain).astype('int32')\n",
    "    input_X = T.matrix()\n",
    "    target_y = T.vector(dtype='int32')\n",
    "    input_shape = (None, Xtrain.shape[1])\n",
    "    \n",
    "    nn = InputLayer(shape =input_shape, input_var=input_X)\n",
    "    nn = DenseLayer(nn, num_units=70, nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    nn = DenseLayer(nn, num_units=20, nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    nn = DenseLayer(nn, num_units=2, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    y_predicted     = get_output(nn)\n",
    "    all_weights     = get_all_params(nn, trainable=True)\n",
    "    loss            = lasagne.objectives.categorical_crossentropy(y_predicted, target_y).mean()\n",
    "    updates         = lasagne.updates.adamax(loss, all_weights)\n",
    "    train_fun       = theano.function([input_X, target_y],loss, updates= updates)\n",
    "    loss_fun        = theano.function([input_X, target_y], loss)\n",
    "    pred            = theano.function([input_X], y_predicted)\n",
    "    \n",
    "    batch_size = 100\n",
    "    for epoch in range(45):\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for batch in iterate_minibatches(Xtrain, ytrain, batchsize=batch_size):\n",
    "            inputs, targets = batch\n",
    "            train_err_batch = train_fun(inputs, targets)\n",
    "            train_err += train_err_batch\n",
    "            train_batches += 1\n",
    "    return pred(Xtrain)[:, 1], pred(Xtest)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping(X, Xtest, y, num=1):\n",
    "    all_mapping = {}\n",
    "    y = y.values\n",
    "    for col in X.columns:\n",
    "        mapping = {}\n",
    "        values = np.unique(X[col])\n",
    "        index = dict(zip(values, range(len(values))))\n",
    "        val_sum = np.zeros(len(values))\n",
    "        val_n = np.zeros(len(values))\n",
    "        x = X[col].values\n",
    "        for i in range(len(y)):\n",
    "            ind = index[x[i]]\n",
    "            val_sum[ind] += y[i]\n",
    "            val_n[ind] += 1\n",
    "        for val in values:\n",
    "            ind = index[val]\n",
    "            if val_n[ind] < num:\n",
    "                mapping[val] = 1\n",
    "            else:\n",
    "                mapping[val] = val_sum[ind] / val_n[ind]\n",
    "        values = np.unique(Xtest[col])\n",
    "        for val in values:\n",
    "            if not val in mapping:\n",
    "                mapping[val] = 1\n",
    "        tmp = sorted([[i, j] for j, i in mapping.items()])\n",
    "        all_mapping[col] = dict(zip([j for i, j in tmp], range(len(mapping))))\n",
    "    return all_mapping\n",
    "\n",
    "def apply_mapping(mapping, X, col_for_mapping):\n",
    "    Xnew = X.copy()\n",
    "    for col in col_for_mapping:\n",
    "        Xnew[col] = X[col].map(mapping[col])\n",
    "    return Xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = KFold(len(X), n_folds=5, shuffle=True, random_state=10)\n",
    "columns = ['marital_status', 'job_position', 'tariff_id', 'education',   'conc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775446514103\n",
      "0.775337769289\n",
      "0.775270838052\n",
      "0.775396983867\n",
      "0.775719968874\n",
      "CPU times: user 1h 7min 40s, sys: 2min 46s, total: 1h 10min 27s\n",
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba = []\n",
    "proba_all = []\n",
    "for i in range(5):\n",
    "    proba_new = pd.Series(index=X.index)\n",
    "    for train, val in cv:\n",
    "\n",
    "        Xtrain = X.iloc[train]\n",
    "        Xval = X.iloc[val]\n",
    "        ytrain = y.iloc[train]\n",
    "        model = xgboost.XGBClassifier(n_estimators=820, \n",
    "                                       max_depth=6, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "\n",
    "        mapping = get_mapping(Xtrain[columns], Xval, ytrain, num=300)\n",
    "        XtrainM = apply_mapping(mapping, Xtrain, columns)\n",
    "        XvalM = apply_mapping(mapping, Xval, columns)\n",
    "\n",
    "        model.fit(XtrainM,  ytrain)\n",
    "        proba_new.iloc[val] = model.predict_proba(XvalM)[:,1]\n",
    "    proba_all.append(proba_new)\n",
    "    print(roc_auc_score(y, proba_new))\n",
    "proba.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775368674236\n",
      "0.775343930934\n",
      "0.775441507929\n",
      "0.775396816553\n",
      "0.775426084544\n",
      "CPU times: user 1h 8min 34s, sys: 2min 57s, total: 1h 11min 32s\n",
      "Wall time: 13min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "for i in range(5):\n",
    "    proba_new = pd.Series(index=X.index)\n",
    "    for train, val in cv:\n",
    "\n",
    "        Xtrain = X.iloc[train]\n",
    "        Xval = X.iloc[val]\n",
    "        ytrain = y.iloc[train]\n",
    "        model = xgboost.XGBClassifier(n_estimators=700, \n",
    "                                       max_depth=7, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "\n",
    "        mapping = get_mapping(Xtrain[columns], Xval, ytrain, num=300)\n",
    "        XtrainM = apply_mapping(mapping, Xtrain, columns)\n",
    "        XvalM = apply_mapping(mapping, Xval, columns)\n",
    "\n",
    "        model.fit(XtrainM,  ytrain)\n",
    "        proba_new.iloc[val] = model.predict_proba(XvalM)[:,1]\n",
    "    proba_all.append(proba_new)\n",
    "    print(roc_auc_score(y, proba_new))\n",
    "proba.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774181498017\n",
      "0.774213559973\n",
      "0.774391893655\n",
      "0.774302265903\n",
      "0.774462212674\n",
      "CPU times: user 1h 8min 36s, sys: 2min 57s, total: 1h 11min 34s\n",
      "Wall time: 13min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "for i in range(5):\n",
    "    proba_new = pd.Series(index=X.index)\n",
    "    for train, val in cv:\n",
    "\n",
    "        Xtrain = X.iloc[train]\n",
    "        Xval = X.iloc[val]\n",
    "        ytrain = y.iloc[train]\n",
    "        model = xgboost.XGBClassifier(n_estimators=700, \n",
    "                                       max_depth=7, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "\n",
    "        #mapping = get_mapping(Xtrain[columns], Xval, ytrain, num=300)\n",
    "        #XtrainM = apply_mapping(mapping, Xtrain, columns)\n",
    "        #XvalM = apply_mapping(mapping, Xval, columns)\n",
    "\n",
    "        model.fit(Xtrain,  ytrain)\n",
    "        proba_new.iloc[val] = model.predict_proba(Xval)[:,1]\n",
    "    proba_all.append(proba_new)\n",
    "    print(roc_auc_score(y, proba_new))\n",
    "proba.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77181444496\n",
      "CPU times: user 1h 36min 40s, sys: 23min 13s, total: 1h 59min 53s\n",
      "Wall time: 33min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_new = pd.Series(index=X.index)\n",
    "nn_proba = []\n",
    "for train, val in cv:\n",
    "    nn_test = []\n",
    "    nn_train = []\n",
    "    for i in range(5):\n",
    "        p_train, p_test = proba_from_nn(X_linear[train], X_linear[val], y.iloc[train])\n",
    "        nn_train.append(p_train)\n",
    "        nn_test.append(p_test)     \n",
    "    nn_proba.append((np.mean(nn_train, axis=0), np.mean(nn_test, axis=0)))\n",
    "    proba_new.iloc[val] = nn_proba[-1][1]\n",
    "proba.append(proba_new)\n",
    "print(roc_auc_score(y, proba_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 9s, sys: 1min 19s, total: 29min 28s\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "\n",
    "for i in range(5):\n",
    "    proba_new = pd.Series(index=X.index)\n",
    "    model = xgboost.XGBClassifier(n_estimators=500, \n",
    "                           max_depth=7, \n",
    "                           colsample_bytree=0.3, \n",
    "                           learning_rate=0.03, \n",
    "                           reg_alpha=4,\n",
    "                           seed=i)\n",
    "    for j, (train, val) in enumerate(cv):\n",
    "\n",
    "        Xtrain = X.iloc[train]\n",
    "        Xval = X.iloc[val]\n",
    "        ytrain = y.iloc[train]\n",
    "        mapping = get_mapping(Xtrain[columns], Xval, ytrain, num=300)\n",
    "        XtrainM = apply_mapping(mapping, Xtrain, columns)\n",
    "        XvalM = apply_mapping(mapping, Xval, columns)\n",
    "        XtrainM['y'] = nn_proba[j][0]\n",
    "        XvalM['y'] = nn_proba[j][1]\n",
    "        \n",
    "        model.fit(XtrainM,  ytrain)\n",
    "        proba_new.iloc[val] = model.predict_proba(XvalM)[:,1]\n",
    "    proba_all.append(proba_new)\n",
    "proba.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775944419116\n",
      "0.776075341713\n",
      "0.775007122488\n",
      "0.77181444496\n",
      "0.775429455416\n"
     ]
    }
   ],
   "source": [
    "for p in proba:\n",
    "    print(roc_auc_score(y, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_blending_coefficient(y, proba, max_iter=200, verbose=False):\n",
    "    B = np.transpose(proba)\n",
    "    n = len(proba)\n",
    "    a = np.array([20]*n)\n",
    "    roc_old = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "    for i in range(max_iter):\n",
    "        a[i % n] += 1\n",
    "        roc_new = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "        if roc_new < roc_old:\n",
    "            a[i % n] += -2\n",
    "            roc_new = roc_auc_score(y, (B * a).mean(axis=1))\n",
    "            if roc_new <= roc_old:\n",
    "                a[i % n] += 1\n",
    "                roc_new = roc_old\n",
    "        roc_old = roc_new\n",
    "        if verbose:\n",
    "            print(a, roc_old)\n",
    "    a[a < 0] = 0\n",
    "    print(roc_old, a)\n",
    "    return a / a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21 20 20 20 20] 0.777839828941\n",
      "[21 21 20 20 20] 0.777843922278\n",
      "[21 21 21 20 20] 0.777845559708\n",
      "[21 21 21 19 20] 0.777849339938\n",
      "[21 21 21 19 19] 0.777851128955\n",
      "[22 21 21 19 19] 0.777851385779\n",
      "[22 22 21 19 19] 0.77785294777\n",
      "[22 22 22 19 19] 0.777853004763\n",
      "[22 22 22 19 19] 0.777853004763\n",
      "[22 22 22 19 18] 0.777853585809\n",
      "[21 22 22 19 18] 0.777854498409\n",
      "[21 23 22 19 18] 0.777855567563\n",
      "[21 23 21 19 18] 0.777855868373\n",
      "[21 23 21 19 18] 0.777855868373\n",
      "[21 23 21 19 17] 0.777856246514\n",
      "[20 23 21 19 17] 0.777857768775\n",
      "[20 24 21 19 17] 0.777858228504\n",
      "[20 24 20 19 17] 0.777858259011\n",
      "[20 24 20 20 17] 0.777858303234\n",
      "[20 24 20 20 16] 0.777858937962\n",
      "[19 24 20 20 16] 0.777859818873\n",
      "[19 25 20 20 16] 0.777861087621\n",
      "[19 25 21 20 16] 0.777861261911\n",
      "[19 25 21 20 16] 0.777861261911\n",
      "[19 25 21 20 16] 0.777861261911\n",
      "[18 25 21 20 16] 0.77786192691\n",
      "[18 26 21 20 16] 0.777863277009\n",
      "[18 26 20 20 16] 0.777863341333\n",
      "[18 26 20 20 16] 0.777863341333\n",
      "[18 26 20 20 15] 0.777863594137\n",
      "[17 26 20 20 15] 0.777864484034\n",
      "[17 27 20 20 15] 0.777865383627\n",
      "[17 27 20 20 15] 0.777865383627\n",
      "[17 27 20 20 15] 0.777865383627\n",
      "[17 27 20 20 15] 0.777865383627\n",
      "[16 27 20 20 15] 0.777866234267\n",
      "[16 28 20 20 15] 0.777866905415\n",
      "[16 28 20 20 15] 0.777866905415\n",
      "[16 28 20 20 15] 0.777866905415\n",
      "[16 28 20 20 16] 0.777867103117\n",
      "[15 28 20 20 16] 0.777867181394\n",
      "[15 29 20 20 16] 0.777868502169\n",
      "[15 29 20 20 16] 0.777868502169\n",
      "[15 29 20 20 16] 0.777868502169\n",
      "[15 29 20 20 16] 0.777868502169\n",
      "[14 29 20 20 16] 0.777868704601\n",
      "[14 30 20 20 16] 0.77786974916\n",
      "[14 30 20 20 16] 0.77786974916\n",
      "[14 30 20 20 16] 0.77786974916\n",
      "[14 30 20 20 15] 0.777870127774\n",
      "[13 30 20 20 15] 0.777870938921\n",
      "[13 31 20 20 15] 0.777871356556\n",
      "[13 31 20 20 15] 0.777871356556\n",
      "[13 31 20 20 15] 0.777871356556\n",
      "[13 31 20 20 15] 0.777871356556\n",
      "[12 31 20 20 15] 0.777872307703\n",
      "[12 32 20 20 15] 0.777872948344\n",
      "[12 32 20 20 15] 0.777872948344\n",
      "[12 32 20 20 15] 0.777872948344\n",
      "[12 32 20 20 15] 0.777872948344\n",
      "[11 32 20 20 15] 0.777873600572\n",
      "[11 33 20 20 15] 0.777874144963\n",
      "[11 33 20 20 15] 0.777874144963\n",
      "[11 33 20 20 15] 0.777874144963\n",
      "[11 33 20 20 15] 0.777874144963\n",
      "[10 33 20 20 15] 0.777874851111\n",
      "[10 34 20 20 15] 0.777875279151\n",
      "[10 34 20 20 15] 0.777875279151\n",
      "[10 34 20 20 15] 0.777875279151\n",
      "[10 34 20 20 15] 0.777875279151\n",
      "[ 9 34 20 20 15] 0.777876102359\n",
      "[ 9 35 20 20 15] 0.777876352088\n",
      "[ 9 35 19 20 15] 0.777876503675\n",
      "[ 9 35 19 20 15] 0.777876503675\n",
      "[ 9 35 19 20 14] 0.777876529925\n",
      "[ 8 35 19 20 14] 0.777877340363\n",
      "[ 8 36 19 20 14] 0.777877417931\n",
      "[ 8 36 18 20 14] 0.777877792052\n",
      "[ 8 36 18 20 14] 0.777877792052\n",
      "[ 8 36 18 20 14] 0.777877792052\n",
      "[ 7 36 18 20 14] 0.777877954045\n",
      "[ 7 37 18 20 14] 0.777878192659\n",
      "[ 7 37 19 20 14] 0.77787822151\n",
      "[ 7 37 19 20 14] 0.77787822151\n",
      "[ 7 37 19 20 14] 0.77787822151\n",
      "[ 6 37 19 20 14] 0.77787870205\n",
      "[ 6 38 19 20 14] 0.777878948705\n",
      "[ 6 38 19 20 14] 0.777878948705\n",
      "[ 6 38 19 20 14] 0.777878948705\n",
      "[ 6 38 19 20 14] 0.777878948705\n",
      "[ 5 38 19 20 14] 0.777879139786\n",
      "[ 5 39 19 20 14] 0.777879380056\n",
      "[ 5 39 19 20 14] 0.777879380056\n",
      "[ 5 39 19 20 14] 0.777879380056\n",
      "[ 5 39 19 20 14] 0.777879380056\n",
      "[ 4 39 19 20 14] 0.777879804785\n",
      "[ 4 39 19 20 14] 0.777879804785\n",
      "[ 4 39 19 20 14] 0.777879804785\n",
      "[ 4 39 19 20 14] 0.777879804785\n",
      "[ 4 39 19 20 14] 0.777879804785\n",
      "[ 3 39 19 20 14] 0.777879906947\n",
      "[ 3 40 19 20 14] 0.777880130426\n",
      "[ 3 40 19 20 14] 0.777880130426\n",
      "[ 3 40 19 20 14] 0.777880130426\n",
      "[ 3 40 19 20 14] 0.777880130426\n",
      "[ 2 40 19 20 14] 0.777880223365\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "[ 2 41 19 20 14] 0.777880591337\n",
      "0.777880591337 [ 2 41 19 20 14]\n"
     ]
    }
   ],
   "source": [
    "a = create_blending_coefficient(y, proba, verbose=True, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 41min 37s, sys: 3min 18s, total: 1h 44min 56s\n",
      "Wall time: 1h 28min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_test = []\n",
    "proba_all = []\n",
    "\n",
    "mapping = get_mapping(X[columns], Xtest, y, num=300)\n",
    "XM = apply_mapping(mapping, X, columns)\n",
    "XtestM = apply_mapping(mapping, Xtest, columns)\n",
    "    \n",
    "for i in range(30):\n",
    "    \n",
    "    model = xgboost.XGBClassifier(n_estimators=820, \n",
    "                                       max_depth=6, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "    model.fit(XM, y)\n",
    "    proba_all.append(model.predict_proba(XtestM)[:,1])\n",
    "proba_test.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 41min 19s, sys: 3min 26s, total: 1h 44min 45s\n",
      "Wall time: 19min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "    \n",
    "for i in range(30):\n",
    "    \n",
    "    model = xgboost.XGBClassifier(n_estimators=700, \n",
    "                                       max_depth=7, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "    model.fit(XM, y)\n",
    "    proba_all.append(model.predict_proba(XtestM)[:,1])\n",
    "proba_test.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 41min 16s, sys: 3min 21s, total: 1h 44min 38s\n",
      "Wall time: 20min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "    \n",
    "for i in range(30):\n",
    "    \n",
    "    model = xgboost.XGBClassifier(n_estimators=700, \n",
    "                                       max_depth=7, \n",
    "                                       colsample_bytree=0.7, \n",
    "                                      subsample=0.9,\n",
    "                                       learning_rate=0.03, \n",
    "                                       reg_alpha=1,\n",
    "                                       seed=i)\n",
    "    model.fit(X, y)\n",
    "    proba_all.append(model.predict_proba(Xtest)[:,1])\n",
    "proba_test.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 38min 2s, sys: 2h 17min 10s, total: 8h 55min 12s\n",
      "Wall time: 3h 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "nn_test = []\n",
    "nn_train = []\n",
    "for i in range(30):\n",
    "    p_train, p_test = proba_from_nn(X_linear, Xtest_linear, y)\n",
    "    nn_train.append(p_train)\n",
    "    nn_test.append(p_test)     \n",
    "    \n",
    "nn_train = np.mean(nn_train, axis=0)\n",
    "nn_test = np.mean(nn_test, axis=0)\n",
    "proba_test.append(nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 30s, sys: 1min 21s, total: 28min 52s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proba_all = []\n",
    "XM['y'] = nn_train\n",
    "XtestM['y'] = nn_test\n",
    "    \n",
    "for i in range(30):\n",
    "    model = xgboost.XGBClassifier(n_estimators=350, \n",
    "                               max_depth=7, \n",
    "                               colsample_bytree=0.3, \n",
    "                               learning_rate=0.03, \n",
    "                               reg_alpha=4,\n",
    "                               seed=i)\n",
    "    model.fit(XM, y)\n",
    "    proba_all.append(model.predict_proba(XtestM)[:,1])\n",
    "proba_test.append(np.mean(proba_all, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(Xtest.index)\n",
    "submission.columns = ['_ID_']\n",
    "submission['_VAL_'] = a.dot(proba_test)\n",
    "submission.to_csv('A.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
